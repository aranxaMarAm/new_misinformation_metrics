{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Mirko Draca and Carlo Schwarz selection of WVS questions and waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pandas in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: seaborn in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: scipy in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: rpy2 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.5.17)\n",
      "Requirement already satisfied: geopandas in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.15.1 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from rpy2->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: jinja2 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from rpy2->-r requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: tzlocal in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from rpy2->-r requirements.txt (line 7)) (5.3)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from geopandas->-r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from geopandas->-r requirements.txt (line 8)) (3.7.1)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from geopandas->-r requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: pycparser in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from cffi>=1.15.1->rpy2->-r requirements.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: certifi in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from pyogrio>=0.7.2->geopandas->-r requirements.txt (line 8)) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aranxamarquezampudia/miniconda3/envs/NLP/lib/python3.10/site-packages (from jinja2->rpy2->-r requirements.txt (line 7)) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_wvs = pd.read_csv('../data/raw/wvs_ts_w1_w7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_survey_responses(df_wvs, question_columns, neutral_values={3, 5}):\n",
    "    \"\"\"\n",
    "    Following Draca & Schwarz (2024) methodology, this function recodes responses from WVS waves 4-7 \n",
    "    into support and oppose indicators, imputes missing values, and filters countries based on response completeness.\n",
    "\n",
    "    Parameters:\n",
    "    - df_wvs (pd.DataFrame): Survey DataFrame.\n",
    "    - question_columns (list): List of columns to transform.\n",
    "    - neutral_values (set): Values representing neutrality (not used here but can be extended).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed DataFrame with support/oppose indicators and country/year.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename and filter for years >= 1999\n",
    "    new_df = df_wvs.rename(columns={\"COUNTRY_ALPHA\": \"country\", \"S020\": \"year\", \"S002VS\": \"wave\"}) \\\n",
    "                   .loc[lambda df: df[\"year\"] >= 1999] \\\n",
    "                   .copy()\n",
    "\n",
    "    # Step 2: Filter for relevant waves\n",
    "    valid_waves = [4, 5, 6, 7]\n",
    "    df_filtered = new_df[new_df[\"wave\"].isin(valid_waves)].copy()\n",
    "\n",
    "    # Step 3: Find countries that appear in at least 3 of the 4 waves\n",
    "    wave_counts = df_filtered.groupby(\"country\")[\"wave\"].nunique()\n",
    "    eligible_countries = wave_counts[wave_counts >= 3].index\n",
    "    df_final = df_filtered[df_filtered[\"country\"].isin(eligible_countries)].copy()\n",
    "\n",
    "    # Step 4: Impute missing values for each question column\n",
    "    for col in question_columns:\n",
    "        valid_values = df_final[df_final[col] >= 0][col]\n",
    "        mean_value = valid_values.mean()\n",
    "        df_final[col] = df_final[col].apply(lambda x: mean_value if x < 0 else x)\n",
    "\n",
    "    # Step 5: Recode into support and oppose\n",
    "    for col in question_columns:\n",
    "        if col == \"C002\":  # 1–3 scale (agree-disagree)\n",
    "            df_final[f\"{col}_support\"] = df_final[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "            df_final[f\"{col}_oppose\"] = df_final[col].apply(lambda x: 1 if x == 2 else 0)\n",
    "        elif col in [\"G006\", \"E069_01\", \"E069_02\", \"E069_04\", \"E069_05\", \"E069_06\",\n",
    "             \"E069_07\", \"E069_08\", \"E069_13\", \"E069_17\"]:  # 1–4 scale\n",
    "             df_final[f\"{col}_support\"] = df_final[col].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "             df_final[f\"{col}_oppose\"] = df_final[col].apply(lambda x: 1 if x in [3, 4] else 0)\n",
    "        elif col in [\"E036\", \"E037\", \"E039\"] or \"F1\" in col:  # 1–10 scale\n",
    "            df_final[f\"{col}_support\"] = df_final[col].apply(lambda x: 1 if x >= 6 else 0)\n",
    "            df_final[f\"{col}_oppose\"] = df_final[col].apply(lambda x: 1 if x <= 4 else 0)\n",
    "        else:  # Binary 0–1\n",
    "            df_final[f\"{col}_support\"] = df_final[col]\n",
    "            df_final[f\"{col}_oppose\"] = 1 - df_final[col]\n",
    "\n",
    "    # Step 6: Keep only relevant columns\n",
    "    interest_columns = [\"country\", \"year\"] + \\\n",
    "                       [f\"{col}_support\" for col in question_columns] + \\\n",
    "                       [f\"{col}_oppose\" for col in question_columns]\n",
    "\n",
    "    return df_final[interest_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "question_columns = [\n",
    "    \"A124_02\", \"A124_06\", \"A124_07\", \"A124_08\", \"A124_09\", \"C002\", \"E036\", \"E037\", \"E039\",\n",
    "    \"F114A\", \"F115\", \"F116\", \"F117\", \"F118\", \"F119\", \"F120\", \"F121\", \"F122\", \"F123\", \"G006\", \n",
    "    \"E069_01\", \"E069_02\", \"E069_04\", \"E069_05\", \"E069_06\", \"E069_07\", \"E069_08\", \"E069_13\", \"E069_17\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vk/c6csf7ws6pj9wy406twfjkfw0000gn/T/ipykernel_31029/4208553163.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{col}_support\"] = df_final[col].apply(lambda x: 1 if x in [1, 2] else 0)\n",
      "/var/folders/vk/c6csf7ws6pj9wy406twfjkfw0000gn/T/ipykernel_31029/4208553163.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{col}_oppose\"] = df_final[col].apply(lambda x: 1 if x in [3, 4] else 0)\n"
     ]
    }
   ],
   "source": [
    "df_encoded = recode_survey_responses(df_wvs, question_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country  year  A124_02_support  A124_06_support  A124_07_support  \\\n",
      "7092     ARG  1999              0.0              0.0              0.0   \n",
      "7093     ARG  1999              0.0              0.0              0.0   \n",
      "7094     ARG  1999              0.0              0.0              1.0   \n",
      "7095     ARG  1999              0.0              0.0              0.0   \n",
      "7096     ARG  1999              0.0              0.0              0.0   \n",
      "\n",
      "      A124_08_support  A124_09_support  C002_support  E036_support  \\\n",
      "7092              0.0              0.0             0             0   \n",
      "7093              1.0              0.0             1             1   \n",
      "7094              1.0              1.0             1             1   \n",
      "7095              0.0              0.0             0             0   \n",
      "7096              0.0              0.0             1             0   \n",
      "\n",
      "      E037_support  ...  G006_oppose  E069_01_oppose  E069_02_oppose  \\\n",
      "7092             1  ...            0               0               1   \n",
      "7093             0  ...            0               0               1   \n",
      "7094             0  ...            0               0               1   \n",
      "7095             0  ...            0               1               1   \n",
      "7096             1  ...            0               1               1   \n",
      "\n",
      "      E069_04_oppose  E069_05_oppose  E069_06_oppose  E069_07_oppose  \\\n",
      "7092               1               1               1               1   \n",
      "7093               1               1               1               1   \n",
      "7094               1               1               1               1   \n",
      "7095               1               1               0               1   \n",
      "7096               0               1               1               1   \n",
      "\n",
      "      E069_08_oppose  E069_13_oppose  E069_17_oppose  \n",
      "7092               1               1               0  \n",
      "7093               1               1               0  \n",
      "7094               1               1               0  \n",
      "7095               1               0               0  \n",
      "7096               1               0               0  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "## Exploring transformed file\n",
    "# Check the first few rows of the transformed DataFrame\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data frame in the four waves\n",
    "\n",
    "# Wave 4 1999 - 2004\n",
    "df_wave4 = df_encoded[df_encoded['year'].between(1999, 2004)].copy()\n",
    "\n",
    "# Wave 5 2005 - 2009\n",
    "df_wave5 = df_encoded[df_encoded['year'].between(2005, 2009)].copy()\n",
    "\n",
    "# Wave 6 2010 - 2014\n",
    "df_wave6 = df_encoded[df_encoded['year'].between(2010, 2014)].copy()\n",
    "\n",
    "# Wave 7 2017 - 2022\n",
    "df_wave7 = df_encoded[df_encoded['year'].between(2017, 2022)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 4 dimensions: (46100, 60)\n",
      "Wave 5 dimensions: (57982, 60)\n",
      "Wave 6 dimensions: (60783, 60)\n",
      "Wave 7 dimensions: (62706, 60)\n"
     ]
    }
   ],
   "source": [
    "## Function to print dimensions of all the frames (wave 4-7)\n",
    "for i, df in enumerate([df_wave4, df_wave5, df_wave6, df_wave7], start=4):\n",
    "    print(f\"Wave {i} dimensions: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of the transformed DataFrames:\n",
      "Wave 4 columns: ['country', 'year', 'A124_02_support', 'A124_06_support', 'A124_07_support', 'A124_08_support', 'A124_09_support', 'C002_support', 'E036_support', 'E037_support', 'E039_support', 'F114A_support', 'F115_support', 'F116_support', 'F117_support', 'F118_support', 'F119_support', 'F120_support', 'F121_support', 'F122_support', 'F123_support', 'G006_support', 'E069_01_support', 'E069_02_support', 'E069_04_support', 'E069_05_support', 'E069_06_support', 'E069_07_support', 'E069_08_support', 'E069_13_support', 'E069_17_support', 'A124_02_oppose', 'A124_06_oppose', 'A124_07_oppose', 'A124_08_oppose', 'A124_09_oppose', 'C002_oppose', 'E036_oppose', 'E037_oppose', 'E039_oppose', 'F114A_oppose', 'F115_oppose', 'F116_oppose', 'F117_oppose', 'F118_oppose', 'F119_oppose', 'F120_oppose', 'F121_oppose', 'F122_oppose', 'F123_oppose', 'G006_oppose', 'E069_01_oppose', 'E069_02_oppose', 'E069_04_oppose', 'E069_05_oppose', 'E069_06_oppose', 'E069_07_oppose', 'E069_08_oppose', 'E069_13_oppose', 'E069_17_oppose']\n",
      "Wave 5 columns: ['country', 'year', 'A124_02_support', 'A124_06_support', 'A124_07_support', 'A124_08_support', 'A124_09_support', 'C002_support', 'E036_support', 'E037_support', 'E039_support', 'F114A_support', 'F115_support', 'F116_support', 'F117_support', 'F118_support', 'F119_support', 'F120_support', 'F121_support', 'F122_support', 'F123_support', 'G006_support', 'E069_01_support', 'E069_02_support', 'E069_04_support', 'E069_05_support', 'E069_06_support', 'E069_07_support', 'E069_08_support', 'E069_13_support', 'E069_17_support', 'A124_02_oppose', 'A124_06_oppose', 'A124_07_oppose', 'A124_08_oppose', 'A124_09_oppose', 'C002_oppose', 'E036_oppose', 'E037_oppose', 'E039_oppose', 'F114A_oppose', 'F115_oppose', 'F116_oppose', 'F117_oppose', 'F118_oppose', 'F119_oppose', 'F120_oppose', 'F121_oppose', 'F122_oppose', 'F123_oppose', 'G006_oppose', 'E069_01_oppose', 'E069_02_oppose', 'E069_04_oppose', 'E069_05_oppose', 'E069_06_oppose', 'E069_07_oppose', 'E069_08_oppose', 'E069_13_oppose', 'E069_17_oppose']\n",
      "Wave 6 columns: ['country', 'year', 'A124_02_support', 'A124_06_support', 'A124_07_support', 'A124_08_support', 'A124_09_support', 'C002_support', 'E036_support', 'E037_support', 'E039_support', 'F114A_support', 'F115_support', 'F116_support', 'F117_support', 'F118_support', 'F119_support', 'F120_support', 'F121_support', 'F122_support', 'F123_support', 'G006_support', 'E069_01_support', 'E069_02_support', 'E069_04_support', 'E069_05_support', 'E069_06_support', 'E069_07_support', 'E069_08_support', 'E069_13_support', 'E069_17_support', 'A124_02_oppose', 'A124_06_oppose', 'A124_07_oppose', 'A124_08_oppose', 'A124_09_oppose', 'C002_oppose', 'E036_oppose', 'E037_oppose', 'E039_oppose', 'F114A_oppose', 'F115_oppose', 'F116_oppose', 'F117_oppose', 'F118_oppose', 'F119_oppose', 'F120_oppose', 'F121_oppose', 'F122_oppose', 'F123_oppose', 'G006_oppose', 'E069_01_oppose', 'E069_02_oppose', 'E069_04_oppose', 'E069_05_oppose', 'E069_06_oppose', 'E069_07_oppose', 'E069_08_oppose', 'E069_13_oppose', 'E069_17_oppose']\n",
      "Wave 7 columns: ['country', 'year', 'A124_02_support', 'A124_06_support', 'A124_07_support', 'A124_08_support', 'A124_09_support', 'C002_support', 'E036_support', 'E037_support', 'E039_support', 'F114A_support', 'F115_support', 'F116_support', 'F117_support', 'F118_support', 'F119_support', 'F120_support', 'F121_support', 'F122_support', 'F123_support', 'G006_support', 'E069_01_support', 'E069_02_support', 'E069_04_support', 'E069_05_support', 'E069_06_support', 'E069_07_support', 'E069_08_support', 'E069_13_support', 'E069_17_support', 'A124_02_oppose', 'A124_06_oppose', 'A124_07_oppose', 'A124_08_oppose', 'A124_09_oppose', 'C002_oppose', 'E036_oppose', 'E037_oppose', 'E039_oppose', 'F114A_oppose', 'F115_oppose', 'F116_oppose', 'F117_oppose', 'F118_oppose', 'F119_oppose', 'F120_oppose', 'F121_oppose', 'F122_oppose', 'F123_oppose', 'G006_oppose', 'E069_01_oppose', 'E069_02_oppose', 'E069_04_oppose', 'E069_05_oppose', 'E069_06_oppose', 'E069_07_oppose', 'E069_08_oppose', 'E069_13_oppose', 'E069_17_oppose']\n"
     ]
    }
   ],
   "source": [
    "# Column names of the transformed DataFrames\n",
    "print(\"Column names of the transformed DataFrames:\")\n",
    "for i, df in enumerate([df_wave4, df_wave5, df_wave6, df_wave7], start=4):\n",
    "    print(f\"Wave {i} columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country  year  A124_02_support  A124_06_support  A124_07_support  \\\n",
      "7092     ARG  1999              0.0              0.0              0.0   \n",
      "7093     ARG  1999              0.0              0.0              0.0   \n",
      "7094     ARG  1999              0.0              0.0              1.0   \n",
      "7095     ARG  1999              0.0              0.0              0.0   \n",
      "7096     ARG  1999              0.0              0.0              0.0   \n",
      "\n",
      "      A124_08_support  A124_09_support  C002_support  E036_support  \\\n",
      "7092              0.0              0.0             0             0   \n",
      "7093              1.0              0.0             1             1   \n",
      "7094              1.0              1.0             1             1   \n",
      "7095              0.0              0.0             0             0   \n",
      "7096              0.0              0.0             1             0   \n",
      "\n",
      "      E037_support  ...  G006_oppose  E069_01_oppose  E069_02_oppose  \\\n",
      "7092             1  ...            0               0               1   \n",
      "7093             0  ...            0               0               1   \n",
      "7094             0  ...            0               0               1   \n",
      "7095             0  ...            0               1               1   \n",
      "7096             1  ...            0               1               1   \n",
      "\n",
      "      E069_04_oppose  E069_05_oppose  E069_06_oppose  E069_07_oppose  \\\n",
      "7092               1               1               1               1   \n",
      "7093               1               1               1               1   \n",
      "7094               1               1               1               1   \n",
      "7095               1               1               0               1   \n",
      "7096               0               1               1               1   \n",
      "\n",
      "      E069_08_oppose  E069_13_oppose  E069_17_oppose  \n",
      "7092               1               1               0  \n",
      "7093               1               1               0  \n",
      "7094               1               1               0  \n",
      "7095               1               0               0  \n",
      "7096               1               0               0  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dictionary from JSON file\n",
    "with open(\"variable_dict.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    variable_dict = json.load(file)\n",
    "\n",
    "# Assuming df_encoded is the DataFrame with the survey data after recoding.\n",
    "# Let's inspect df_encoded for LDA\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Este sí jaló\n",
    "\n",
    "# Prepare Data for LDA (Remove Country & Year for now)\n",
    "lda_data = df_encoded.drop(columns=[\"country\", \"year\"])\n",
    "\n",
    "# Fit LDA with 10 Ideological Groups\n",
    "num_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics,\n",
    "                                    doc_topic_prior = 0.25 ,\n",
    "                                    topic_word_prior = 0.1 ,\n",
    "                                    learning_method='online', # online updating not batch faster\n",
    "                                    learning_decay=0.7, # how soon parameters are forgotten\n",
    "                                    learning_offset=10.0, #downweights early learning steppts\n",
    "                                    max_iter=50, # max number of iterations default 10 (iterations in M step)\n",
    "                                    batch_size=1000, #size of batch to use\n",
    "                                    evaluate_every=-1, # evaluate perplexity -1 is off\n",
    "                                    mean_change_tol=0.001, # stopping tolerance for updating in E-step\n",
    "                                    max_doc_update_iter=300, # maximum number of iterations in E-step (iterations over batch)\n",
    "                                    n_jobs=-1, #number of cpu to use\n",
    "                                    random_state=25) #random state, original was in 42 \n",
    "lda_matrix = lda_model.fit_transform(lda_data)\n",
    "\n",
    "# Extract Topic-Feature Importance\n",
    "feature_names = lda_data.columns\n",
    "topic_words = pd.DataFrame(lda_model.components_, columns=feature_names)\n",
    "\n",
    "# Normalize the Importance Scores\n",
    "topic_words = topic_words.div(topic_words.sum(axis=1), axis=0)\n",
    "topic_words = topic_words.T  # Transpose for better visualization\n",
    "topic_words.columns = [f\"Ideology_{i+1}\" for i in range(num_topics)]\n",
    "\n",
    "#### Este sí jaló"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ideology_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_5",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "996c5c1b-59a5-4915-95a4-541e86a2ab5a",
       "rows": [
        [
         "0",
         "A124_07_support",
         "F119_oppose",
         "F121_support",
         "F115_support",
         "A124_06_support"
        ],
        [
         "1",
         "A124_09_support",
         "F123_oppose",
         "A124_02_oppose",
         "F114A_support",
         "A124_02_support"
        ],
        [
         "2",
         "A124_08_support",
         "F120_oppose",
         "F117_oppose",
         "F116_support",
         "F119_oppose"
        ],
        [
         "3",
         "F118_oppose",
         "A124_02_oppose",
         "A124_06_oppose",
         "F121_support",
         "F123_oppose"
        ],
        [
         "4",
         "F119_oppose",
         "A124_06_oppose",
         "A124_09_oppose",
         "F120_support",
         "F117_oppose"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ideology_1</th>\n",
       "      <th>Ideology_2</th>\n",
       "      <th>Ideology_3</th>\n",
       "      <th>Ideology_4</th>\n",
       "      <th>Ideology_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A124_07_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "      <td>F115_support</td>\n",
       "      <td>A124_06_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A124_09_support</td>\n",
       "      <td>F123_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>F114A_support</td>\n",
       "      <td>A124_02_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A124_08_support</td>\n",
       "      <td>F120_oppose</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>F116_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F118_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "      <td>F123_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>A124_09_oppose</td>\n",
       "      <td>F120_support</td>\n",
       "      <td>F117_oppose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ideology_1      Ideology_2      Ideology_3     Ideology_4  \\\n",
       "0  A124_07_support     F119_oppose    F121_support   F115_support   \n",
       "1  A124_09_support     F123_oppose  A124_02_oppose  F114A_support   \n",
       "2  A124_08_support     F120_oppose     F117_oppose   F116_support   \n",
       "3      F118_oppose  A124_02_oppose  A124_06_oppose   F121_support   \n",
       "4      F119_oppose  A124_06_oppose  A124_09_oppose   F120_support   \n",
       "\n",
       "        Ideology_5  \n",
       "0  A124_06_support  \n",
       "1  A124_02_support  \n",
       "2      F119_oppose  \n",
       "3      F123_oppose  \n",
       "4      F117_oppose  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Top Issues for Each Ideology\n",
    "top_issues = topic_words.apply(lambda x: x.nlargest(5).index.tolist(), axis=0)\n",
    "top_issues\n",
    "\n",
    "# Save the descriptive DataFrame to a CSV file\n",
    "top_issues.to_csv('top_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Folders for the results\n",
    "\n",
    "# Subfolders exist\n",
    "os.makedirs(\"../reports/lda_evaluation\", exist_ok=True)\n",
    "os.makedirs(\"../reports/top_issues\", exist_ok=True)\n",
    "\n",
    "# Example for saving evaluation results\n",
    "#eval_df.to_csv(f\"reports/lda_evaluation/wave{wave_number}_evaluation.csv\", index=False)\n",
    "\n",
    "# Later when saving top issues:\n",
    "#top_issues_df.to_csv(f\"reports/top_issues/wave{wave_number}_top_issues.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "# Setup\n",
    "num_folds = 10\n",
    "topic_range = range(1, 11)  # K = 1 to 10\n",
    "data_folder = \"data\"\n",
    "results_folder = \"../reports/model_evaluation\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "def compute_npmi(issue_list, test_data):\n",
    "    \"\"\"Compute NPMI for a list of top issues using test data.\"\"\"\n",
    "    N = len(test_data)\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    binary_data = test_data[issue_list].astype(int)\n",
    "    issue_counts = binary_data.sum(axis=0).to_dict()\n",
    "\n",
    "    npmi_scores = []\n",
    "    for i, j in combinations(issue_list, 2):\n",
    "        p_i = issue_counts[i] / N\n",
    "        p_j = issue_counts[j] / N\n",
    "        p_ij = ((binary_data[i] & binary_data[j]).sum()) / N\n",
    "\n",
    "        if p_ij > 0:\n",
    "            pmi = np.log(p_ij / (p_i * p_j + epsilon))\n",
    "            npmi = pmi / (-np.log(p_ij + epsilon))\n",
    "            npmi_scores.append(npmi)\n",
    "\n",
    "    return np.mean(npmi_scores) if npmi_scores else 0\n",
    "\n",
    "def evaluate_model_with_npmi(model, test_data, train_data):\n",
    "    \"\"\"Evaluate LDA model using average NPMI across all topics.\"\"\"\n",
    "    feature_names = train_data.columns\n",
    "    topic_words = pd.DataFrame(model.components_, columns=feature_names)\n",
    "    top_issues_per_topic = topic_words.apply(lambda x: x.nlargest(5).index.tolist(), axis=1)\n",
    "\n",
    "    topic_npmis = [compute_npmi(issue_list, test_data) for issue_list in top_issues_per_topic]\n",
    "    return np.mean(topic_npmis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌊 Processing Wave 4\n",
      "📂 Fold 1/10\n",
      "📂 Fold 2/10\n",
      "📂 Fold 3/10\n",
      "📂 Fold 4/10\n",
      "📂 Fold 5/10\n",
      "📂 Fold 6/10\n",
      "📂 Fold 7/10\n",
      "📂 Fold 8/10\n",
      "📂 Fold 9/10\n",
      "📂 Fold 10/10\n",
      "🏆 Optimal number of topics for Wave 4: K=4\n",
      "✅ Saved evaluation results for Wave 4\n",
      "\n",
      "🌊 Processing Wave 5\n",
      "📂 Fold 1/10\n",
      "📂 Fold 2/10\n",
      "📂 Fold 3/10\n",
      "📂 Fold 4/10\n",
      "📂 Fold 5/10\n",
      "📂 Fold 6/10\n",
      "📂 Fold 7/10\n",
      "📂 Fold 8/10\n",
      "📂 Fold 9/10\n",
      "📂 Fold 10/10\n",
      "🏆 Optimal number of topics for Wave 5: K=7\n",
      "✅ Saved evaluation results for Wave 5\n",
      "\n",
      "🌊 Processing Wave 6\n",
      "📂 Fold 1/10\n",
      "📂 Fold 2/10\n",
      "📂 Fold 3/10\n",
      "📂 Fold 4/10\n",
      "📂 Fold 5/10\n",
      "📂 Fold 6/10\n",
      "📂 Fold 7/10\n",
      "📂 Fold 8/10\n",
      "📂 Fold 9/10\n",
      "📂 Fold 10/10\n",
      "🏆 Optimal number of topics for Wave 6: K=3\n",
      "✅ Saved evaluation results for Wave 6\n",
      "\n",
      "🌊 Processing Wave 7\n",
      "📂 Fold 1/10\n",
      "📂 Fold 2/10\n",
      "📂 Fold 3/10\n",
      "📂 Fold 4/10\n",
      "📂 Fold 5/10\n",
      "📂 Fold 6/10\n",
      "📂 Fold 7/10\n",
      "📂 Fold 8/10\n",
      "📂 Fold 9/10\n",
      "📂 Fold 10/10\n",
      "🏆 Optimal number of topics for Wave 7: K=3\n",
      "✅ Saved evaluation results for Wave 7\n",
      "\n",
      "🎯 Done! All waves processed using NPMI evaluation.\n"
     ]
    }
   ],
   "source": [
    "def process_wave_from_df(wave_number, df_wave):\n",
    "    print(f\"\\n🌊 Processing Wave {wave_number}\")\n",
    "\n",
    "    # Drop metadata columns so that LDA only uses issue variables\n",
    "    lda_data = df_wave.drop(columns=[\"country\", \"year\"])\n",
    "\n",
    "    # Initialize K-Fold cross-validator\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # To store NPMI evaluation scores across folds and topic numbers\n",
    "    evaluation_matrix = np.zeros((num_folds, len(topic_range)))\n",
    "    npmi_scores_per_topic = {k: [] for k in topic_range}\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(lda_data)):\n",
    "        print(f\"📂 Fold {fold_idx + 1}/{num_folds}\")\n",
    "\n",
    "        train_data = lda_data.iloc[train_idx]\n",
    "        test_data = lda_data.iloc[test_idx]\n",
    "\n",
    "        for k_idx, n_topics in enumerate(topic_range):\n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=n_topics,\n",
    "                doc_topic_prior=0.25,\n",
    "                topic_word_prior=0.1,\n",
    "                learning_method='online',\n",
    "                learning_decay=0.7,\n",
    "                learning_offset=10.0,\n",
    "                max_iter=20,\n",
    "                batch_size=1000,\n",
    "                evaluate_every=-1,\n",
    "                mean_change_tol=0.001,\n",
    "                max_doc_update_iter=100,\n",
    "                n_jobs=-1,  # Uses all cores for this model\n",
    "                random_state=25\n",
    "            )\n",
    "            lda.fit(train_data)\n",
    "\n",
    "            # Evaluate using NPMI with held-out test data\n",
    "            npmi_score = evaluate_model_with_npmi(lda, test_data, train_data)\n",
    "            evaluation_matrix[fold_idx, k_idx] = npmi_score\n",
    "            npmi_scores_per_topic[n_topics].append(npmi_score)\n",
    "\n",
    "    # Compute the average NPMI across all folds for each topic count\n",
    "    avg_npmis = {k: np.mean(npmi_scores_per_topic[k]) for k in topic_range}\n",
    "\n",
    "    # Identify the optimal number of topics\n",
    "    optimal_k = max(avg_npmis, key=avg_npmis.get)\n",
    "    print(f\"🏆 Optimal number of topics for Wave {wave_number}: K={optimal_k}\")\n",
    "\n",
    "    # Save evaluation results\n",
    "    eval_df = pd.DataFrame(evaluation_matrix, columns=[f\"K={k}\" for k in topic_range])\n",
    "    eval_df.to_csv(f\"{results_folder}/wave{wave_number}_evaluation.csv\", index=False)\n",
    "    print(f\"✅ Saved evaluation results for Wave {wave_number}\")\n",
    "\n",
    "\n",
    "# Run for waves 4–7 sequentially to avoid CPU overload\n",
    "for wave_number, df in zip(range(4, 8), [df_wave4, df_wave5, df_wave6, df_wave7]):\n",
    "    process_wave_from_df(wave_number, df)\n",
    "\n",
    "print(\"\\n🎯 Done! All waves processed using NPMI evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Topic-Feature Importance\n",
    "feature_names = lda_data.columns\n",
    "topic_words = pd.DataFrame(lda_model.components_, columns=feature_names)\n",
    "\n",
    "# Normalize the Importance Scores\n",
    "topic_words = topic_words.div(topic_words.sum(axis=1), axis=0)\n",
    "topic_words = topic_words.T  # Transpose for better visualization\n",
    "topic_words.columns = [f\"Ideology_{i+1}\" for i in range(num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Top Issues for Each Ideology\n",
    "top_issues = topic_words.apply(lambda x: x.nlargest(10).index.tolist(), axis=0)\n",
    "top_issues\n",
    "\n",
    "# Save the descriptive DataFrame to a CSV file\n",
    "top_issues.to_csv('top_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ideology_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_5",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_6",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_7",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_8",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_9",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_10",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8a8baa2e-d787-445b-ab97-ae73a012d884",
       "rows": [
        [
         "0",
         "F114A_support",
         "G006_oppose",
         "E069_06_oppose",
         "A124_09_support",
         "F118_support",
         "E069_17_support",
         "A124_07_support",
         "E069_02_oppose",
         "A124_07_oppose",
         "F122_support"
        ],
        [
         "1",
         "F115_support",
         "E069_01_oppose",
         "E069_17_oppose",
         "F118_oppose",
         "E039_support",
         "E069_08_support",
         "A124_09_support",
         "E069_06_oppose",
         "F120_oppose",
         "F121_support"
        ],
        [
         "2",
         "F116_support",
         "E069_02_oppose",
         "E069_04_support",
         "F120_oppose",
         "F121_support",
         "E069_06_support",
         "F118_oppose",
         "E069_07_oppose",
         "A124_09_oppose",
         "A124_09_oppose"
        ],
        [
         "3",
         "F117_support",
         "E037_support",
         "E069_13_support",
         "F119_oppose",
         "A124_08_oppose",
         "E069_07_support",
         "E039_oppose",
         "E069_08_oppose",
         "F118_oppose",
         "F118_support"
        ],
        [
         "4",
         "F122_support",
         "E069_07_oppose",
         "E069_05_support",
         "A124_08_support",
         "A124_09_oppose",
         "E069_13_support",
         "F119_oppose",
         "E069_04_oppose",
         "F119_oppose",
         "F114A_oppose"
        ],
        [
         "5",
         "F123_support",
         "E069_13_oppose",
         "E069_07_oppose",
         "F123_oppose",
         "A124_07_oppose",
         "E069_05_support",
         "F120_oppose",
         "E069_17_oppose",
         "F122_oppose",
         "F120_support"
        ],
        [
         "6",
         "F121_support",
         "A124_02_oppose",
         "E069_08_oppose",
         "F117_oppose",
         "E036_support",
         "E069_04_support",
         "A124_06_support",
         "E069_05_oppose",
         "F123_oppose",
         "F117_oppose"
        ],
        [
         "7",
         "A124_08_support",
         "E069_08_oppose",
         "E069_02_support",
         "F122_oppose",
         "F119_support",
         "E069_02_support",
         "F117_oppose",
         "E069_13_oppose",
         "F117_oppose",
         "A124_07_oppose"
        ],
        [
         "8",
         "A124_07_support",
         "A124_06_oppose",
         "E069_01_support",
         "F116_oppose",
         "F120_support",
         "A124_02_oppose",
         "F115_oppose",
         "E069_01_oppose",
         "F116_oppose",
         "F116_oppose"
        ],
        [
         "9",
         "A124_09_support",
         "F117_oppose",
         "A124_02_oppose",
         "A124_02_oppose",
         "E069_02_oppose",
         "A124_06_oppose",
         "F123_oppose",
         "A124_02_oppose",
         "E039_oppose",
         "E039_oppose"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ideology_1</th>\n",
       "      <th>Ideology_2</th>\n",
       "      <th>Ideology_3</th>\n",
       "      <th>Ideology_4</th>\n",
       "      <th>Ideology_5</th>\n",
       "      <th>Ideology_6</th>\n",
       "      <th>Ideology_7</th>\n",
       "      <th>Ideology_8</th>\n",
       "      <th>Ideology_9</th>\n",
       "      <th>Ideology_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F114A_support</td>\n",
       "      <td>G006_oppose</td>\n",
       "      <td>E069_06_oppose</td>\n",
       "      <td>A124_09_support</td>\n",
       "      <td>F118_support</td>\n",
       "      <td>E069_17_support</td>\n",
       "      <td>A124_07_support</td>\n",
       "      <td>E069_02_oppose</td>\n",
       "      <td>A124_07_oppose</td>\n",
       "      <td>F122_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F115_support</td>\n",
       "      <td>E069_01_oppose</td>\n",
       "      <td>E069_17_oppose</td>\n",
       "      <td>F118_oppose</td>\n",
       "      <td>E039_support</td>\n",
       "      <td>E069_08_support</td>\n",
       "      <td>A124_09_support</td>\n",
       "      <td>E069_06_oppose</td>\n",
       "      <td>F120_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F116_support</td>\n",
       "      <td>E069_02_oppose</td>\n",
       "      <td>E069_04_support</td>\n",
       "      <td>F120_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "      <td>E069_06_support</td>\n",
       "      <td>F118_oppose</td>\n",
       "      <td>E069_07_oppose</td>\n",
       "      <td>A124_09_oppose</td>\n",
       "      <td>A124_09_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F117_support</td>\n",
       "      <td>E037_support</td>\n",
       "      <td>E069_13_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>A124_08_oppose</td>\n",
       "      <td>E069_07_support</td>\n",
       "      <td>E039_oppose</td>\n",
       "      <td>E069_08_oppose</td>\n",
       "      <td>F118_oppose</td>\n",
       "      <td>F118_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F122_support</td>\n",
       "      <td>E069_07_oppose</td>\n",
       "      <td>E069_05_support</td>\n",
       "      <td>A124_08_support</td>\n",
       "      <td>A124_09_oppose</td>\n",
       "      <td>E069_13_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>E069_04_oppose</td>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>F114A_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F123_support</td>\n",
       "      <td>E069_13_oppose</td>\n",
       "      <td>E069_07_oppose</td>\n",
       "      <td>F123_oppose</td>\n",
       "      <td>A124_07_oppose</td>\n",
       "      <td>E069_05_support</td>\n",
       "      <td>F120_oppose</td>\n",
       "      <td>E069_17_oppose</td>\n",
       "      <td>F122_oppose</td>\n",
       "      <td>F120_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F121_support</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>E069_08_oppose</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>E036_support</td>\n",
       "      <td>E069_04_support</td>\n",
       "      <td>A124_06_support</td>\n",
       "      <td>E069_05_oppose</td>\n",
       "      <td>F123_oppose</td>\n",
       "      <td>F117_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A124_08_support</td>\n",
       "      <td>E069_08_oppose</td>\n",
       "      <td>E069_02_support</td>\n",
       "      <td>F122_oppose</td>\n",
       "      <td>F119_support</td>\n",
       "      <td>E069_02_support</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>E069_13_oppose</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>A124_07_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A124_07_support</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>E069_01_support</td>\n",
       "      <td>F116_oppose</td>\n",
       "      <td>F120_support</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>F115_oppose</td>\n",
       "      <td>E069_01_oppose</td>\n",
       "      <td>F116_oppose</td>\n",
       "      <td>F116_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A124_09_support</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>E069_02_oppose</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>F123_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>E039_oppose</td>\n",
       "      <td>E039_oppose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ideology_1      Ideology_2       Ideology_3       Ideology_4  \\\n",
       "0    F114A_support     G006_oppose   E069_06_oppose  A124_09_support   \n",
       "1     F115_support  E069_01_oppose   E069_17_oppose      F118_oppose   \n",
       "2     F116_support  E069_02_oppose  E069_04_support      F120_oppose   \n",
       "3     F117_support    E037_support  E069_13_support      F119_oppose   \n",
       "4     F122_support  E069_07_oppose  E069_05_support  A124_08_support   \n",
       "5     F123_support  E069_13_oppose   E069_07_oppose      F123_oppose   \n",
       "6     F121_support  A124_02_oppose   E069_08_oppose      F117_oppose   \n",
       "7  A124_08_support  E069_08_oppose  E069_02_support      F122_oppose   \n",
       "8  A124_07_support  A124_06_oppose  E069_01_support      F116_oppose   \n",
       "9  A124_09_support     F117_oppose   A124_02_oppose   A124_02_oppose   \n",
       "\n",
       "       Ideology_5       Ideology_6       Ideology_7      Ideology_8  \\\n",
       "0    F118_support  E069_17_support  A124_07_support  E069_02_oppose   \n",
       "1    E039_support  E069_08_support  A124_09_support  E069_06_oppose   \n",
       "2    F121_support  E069_06_support      F118_oppose  E069_07_oppose   \n",
       "3  A124_08_oppose  E069_07_support      E039_oppose  E069_08_oppose   \n",
       "4  A124_09_oppose  E069_13_support      F119_oppose  E069_04_oppose   \n",
       "5  A124_07_oppose  E069_05_support      F120_oppose  E069_17_oppose   \n",
       "6    E036_support  E069_04_support  A124_06_support  E069_05_oppose   \n",
       "7    F119_support  E069_02_support      F117_oppose  E069_13_oppose   \n",
       "8    F120_support   A124_02_oppose      F115_oppose  E069_01_oppose   \n",
       "9  E069_02_oppose   A124_06_oppose      F123_oppose  A124_02_oppose   \n",
       "\n",
       "       Ideology_9     Ideology_10  \n",
       "0  A124_07_oppose    F122_support  \n",
       "1     F120_oppose    F121_support  \n",
       "2  A124_09_oppose  A124_09_oppose  \n",
       "3     F118_oppose    F118_support  \n",
       "4     F119_oppose    F114A_oppose  \n",
       "5     F122_oppose    F120_support  \n",
       "6     F123_oppose     F117_oppose  \n",
       "7     F117_oppose  A124_07_oppose  \n",
       "8     F116_oppose     F116_oppose  \n",
       "9     E039_oppose     E039_oppose  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mergin back the results to country and year \n",
    "for wave_df in [df_wave4, df_wave5, df_wave6, df_wave7]:\n",
    "    lda_data = wave_df.drop(columns=[\"country\", \"year\"])\n",
    "    lda.fit(lda_data)\n",
    "    topic_dist = lda.transform(lda_data)\n",
    "    topic_df = pd.DataFrame(topic_dist, columns=[f\"Topic_{i+1}\" for i in range(topic_dist.shape[1])])\n",
    "    merged = pd.concat([wave_df.reset_index(drop=True), topic_df], axis=1)\n",
    "\n",
    "    # Optionally save it\n",
    "    year_range = f\"{wave_df['year'].min()}_{wave_df['year'].max()}\"\n",
    "    merged.to_csv(f\"../reports/merged_wave_{year_range}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
