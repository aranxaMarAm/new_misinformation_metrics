{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Mirko Draca and Carlo Schwarz selection of WVS questions and waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_wvs = pd.read_csv('../master_thesis_R/wvs_ts_w1_w7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def recode_survey_responses(df, question_columns, neutral_values={3, 5}):\n",
    "    \"\"\"\n",
    "    Followin Draca & Schwarz (2024) methodology, this function recodes responses  from all waves from the World Value Surve into two indicator variables (support and oppose), \n",
    "    imputing missing values, and calculating shares.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Survey DataFrame.\n",
    "    - question_columns (list): List of columns to transform.\n",
    "    - neutral_values (set): Values representing neutrality.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed DataFrame with support/oppose indicators.\n",
    "    \"\"\"\n",
    "    new_df = df_wvs.rename(columns={\"COUNTRY_ALPHA\": \"country\", \"S020\": \"year\"}).copy()\n",
    "\n",
    "    # Impute missing values (negative values) with the sample mean of non-missing data\n",
    "    for col in question_columns:\n",
    "        # Impute missing values\n",
    "        valid_values = new_df[new_df[col] >= 0][col]  # Exclude negative values (missing data)\n",
    "        mean_value = valid_values.mean()\n",
    "        new_df[col] = new_df[col].apply(lambda x: mean_value if x < 0 else x)\n",
    "    \n",
    "    for col in question_columns:\n",
    "        # Recode based on specific column logic\n",
    "        if col == \"C002\":  # 1–3 scale (agree-disagree)\n",
    "            new_df[f\"{col}_support\"] = new_df[col].apply(lambda x: 1 if x == 1 else 0)  # 1 means agree (support)\n",
    "            new_df[f\"{col}_oppose\"] = new_df[col].apply(lambda x: 1 if x == 2 else 0)  # 2 means disagree (oppose)\n",
    "        elif col == \"G006\":  # 1–4 scale (1 and 2 = support, 3 and 4 = oppose)\n",
    "            new_df[f\"{col}_support\"] = new_df[col].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "            new_df[f\"{col}_oppose\"] = new_df[col].apply(lambda x: 1 if x in [3, 4] else 0)\n",
    "        elif col in [\"E036\", \"E037\", \"E039\"]:  # 1–10 scale\n",
    "            new_df[f\"{col}_support\"] = new_df[col].apply(lambda x: 1 if x >= 6 else 0)  # 6-10 = support\n",
    "            new_df[f\"{col}_oppose\"] = new_df[col].apply(lambda x: 1 if x <= 4 else 0)  # 1-4 = oppose\n",
    "        elif \"F1\" in col:  # 1–10 scale for F1... questions\n",
    "            new_df[f\"{col}_support\"] = new_df[col].apply(lambda x: 1 if x >= 6 else 0)  # 6-10 = support\n",
    "            new_df[f\"{col}_oppose\"] = new_df[col].apply(lambda x: 1 if x <= 4 else 0)  # 1-4 = oppose\n",
    "        else:  # Binary 0–1\n",
    "            new_df[f\"{col}_support\"] = new_df[col]\n",
    "            new_df[f\"{col}_oppose\"] = 1 - new_df[col]  # If it's binary, 1 - value gives the opposite\n",
    "\n",
    "    # Keep only relevant columns (support/oppose + country, year)\n",
    "    interest_columns = [\"country\", \"year\"] + [f\"{col}_support\" for col in question_columns] + [f\"{col}_oppose\" for col in question_columns]\n",
    "    new_df = new_df[interest_columns]\n",
    "    \n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "question_columns = [\"A124_02\", \"A124_06\", \"A124_07\", \"A124_08\", \"A124_09\", \n",
    "                    \"C002\", \"E036\", \"E037\", \"E039\", \"F114A\", \"F115\", \"F116\", \n",
    "                    \"F117\", \"F118\", \"F119\", \"F120\", \"F121\", \"F122\", \"F123\"]\n",
    "\n",
    "df_encoded = recode_survey_responses(df_wvs, question_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  year  A124_02_support  A124_06_support  A124_07_support  \\\n",
      "0     ALB  1998              0.0              0.0              1.0   \n",
      "1     ALB  1998              0.0              0.0              1.0   \n",
      "2     ALB  1998              0.0              0.0              1.0   \n",
      "3     ALB  1998              0.0              0.0              1.0   \n",
      "4     ALB  1998              0.0              0.0              1.0   \n",
      "\n",
      "   A124_08_support  A124_09_support  C002_support  E036_support  E037_support  \\\n",
      "0              1.0              1.0             1             0             1   \n",
      "1              1.0              1.0             1             0             0   \n",
      "2              1.0              1.0             1             0             1   \n",
      "3              1.0              1.0             1             0             1   \n",
      "4              1.0              1.0             1             0             1   \n",
      "\n",
      "   ...  F114A_oppose  F115_oppose  F116_oppose  F117_oppose  F118_oppose  \\\n",
      "0  ...             0            1            1            1            1   \n",
      "1  ...             0            1            1            1            1   \n",
      "2  ...             0            1            1            1            1   \n",
      "3  ...             0            1            1            1            1   \n",
      "4  ...             0            1            1            1            1   \n",
      "\n",
      "   F119_oppose  F120_oppose  F121_oppose  F122_oppose  F123_oppose  \n",
      "0            1            0            0            1            1  \n",
      "1            1            0            0            1            1  \n",
      "2            1            0            0            1            1  \n",
      "3            1            1            1            1            1  \n",
      "4            1            1            1            1            1  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "## Exploring transformed file\n",
    "# Check the first few rows of the transformed DataFrame\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new DataFrame with the recoded responses\n",
    "grouped_df = recode_survey_responses(df_wvs, question_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  year  A124_02_support  A124_06_support  A124_07_support  \\\n",
      "0     ALB  1998              0.0              0.0              1.0   \n",
      "1     ALB  1998              0.0              0.0              1.0   \n",
      "2     ALB  1998              0.0              0.0              1.0   \n",
      "3     ALB  1998              0.0              0.0              1.0   \n",
      "4     ALB  1998              0.0              0.0              1.0   \n",
      "\n",
      "   A124_08_support  A124_09_support  C002_support  E036_support  E037_support  \\\n",
      "0              1.0              1.0             1             0             1   \n",
      "1              1.0              1.0             1             0             0   \n",
      "2              1.0              1.0             1             0             1   \n",
      "3              1.0              1.0             1             0             1   \n",
      "4              1.0              1.0             1             0             1   \n",
      "\n",
      "   ...  F114A_oppose  F115_oppose  F116_oppose  F117_oppose  F118_oppose  \\\n",
      "0  ...             0            1            1            1            1   \n",
      "1  ...             0            1            1            1            1   \n",
      "2  ...             0            1            1            1            1   \n",
      "3  ...             0            1            1            1            1   \n",
      "4  ...             0            1            1            1            1   \n",
      "\n",
      "   F119_oppose  F120_oppose  F121_oppose  F122_oppose  F123_oppose  \n",
      "0            1            0            0            1            1  \n",
      "1            1            0            0            1            1  \n",
      "2            1            0            0            1            1  \n",
      "3            1            1            1            1            1  \n",
      "4            1            1            1            1            1  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dictionary from JSON file\n",
    "with open(\"variable_dict.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    variable_dict = json.load(file)\n",
    "\n",
    "# Assuming df_encoded is the DataFrame with the survey data after recoding.\n",
    "# Let's inspect df_encoded for LDA\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for LDA (Remove Country & Year for now)\n",
    "lda_data = df_encoded.drop(columns=[\"country\", \"year\"])\n",
    "\n",
    "# Fit LDA with 10 Ideological Groups (you can tweak num_topics as needed)\n",
    "num_topics = 10\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_matrix = lda_model.fit_transform(lda_data)\n",
    "\n",
    "# Extract Topic-Feature Importance\n",
    "feature_names = lda_data.columns\n",
    "topic_words = pd.DataFrame(lda_model.components_, columns=feature_names)\n",
    "\n",
    "# Normalize the Importance Scores\n",
    "topic_words = topic_words.div(topic_words.sum(axis=1), axis=0)\n",
    "topic_words = topic_words.T  # Transpose for better visualization\n",
    "topic_words.columns = [f\"Ideology_{i+1}\" for i in range(num_topics)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ideology_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ideology_5",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "996c5c1b-59a5-4915-95a4-541e86a2ab5a",
       "rows": [
        [
         "0",
         "A124_07_support",
         "F119_oppose",
         "F121_support",
         "F115_support",
         "A124_06_support"
        ],
        [
         "1",
         "A124_09_support",
         "F123_oppose",
         "A124_02_oppose",
         "F114A_support",
         "A124_02_support"
        ],
        [
         "2",
         "A124_08_support",
         "F120_oppose",
         "F117_oppose",
         "F116_support",
         "F119_oppose"
        ],
        [
         "3",
         "F118_oppose",
         "A124_02_oppose",
         "A124_06_oppose",
         "F121_support",
         "F123_oppose"
        ],
        [
         "4",
         "F119_oppose",
         "A124_06_oppose",
         "A124_09_oppose",
         "F120_support",
         "F117_oppose"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ideology_1</th>\n",
       "      <th>Ideology_2</th>\n",
       "      <th>Ideology_3</th>\n",
       "      <th>Ideology_4</th>\n",
       "      <th>Ideology_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A124_07_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "      <td>F115_support</td>\n",
       "      <td>A124_06_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A124_09_support</td>\n",
       "      <td>F123_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>F114A_support</td>\n",
       "      <td>A124_02_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A124_08_support</td>\n",
       "      <td>F120_oppose</td>\n",
       "      <td>F117_oppose</td>\n",
       "      <td>F116_support</td>\n",
       "      <td>F119_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F118_oppose</td>\n",
       "      <td>A124_02_oppose</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>F121_support</td>\n",
       "      <td>F123_oppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F119_oppose</td>\n",
       "      <td>A124_06_oppose</td>\n",
       "      <td>A124_09_oppose</td>\n",
       "      <td>F120_support</td>\n",
       "      <td>F117_oppose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ideology_1      Ideology_2      Ideology_3     Ideology_4  \\\n",
       "0  A124_07_support     F119_oppose    F121_support   F115_support   \n",
       "1  A124_09_support     F123_oppose  A124_02_oppose  F114A_support   \n",
       "2  A124_08_support     F120_oppose     F117_oppose   F116_support   \n",
       "3      F118_oppose  A124_02_oppose  A124_06_oppose   F121_support   \n",
       "4      F119_oppose  A124_06_oppose  A124_09_oppose   F120_support   \n",
       "\n",
       "        Ideology_5  \n",
       "0  A124_06_support  \n",
       "1  A124_02_support  \n",
       "2      F119_oppose  \n",
       "3      F123_oppose  \n",
       "4      F117_oppose  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Top Issues for Each Ideology\n",
    "top_issues = topic_words.apply(lambda x: x.nlargest(5).index.tolist(), axis=0)\n",
    "top_issues\n",
    "\n",
    "# Save the descriptive DataFrame to a CSV file\n",
    "top_issues.to_csv('top_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Ideology_1  \\\n",
      "0  People with AIDS as neighbors_support   \n",
      "1       Homosexuals as neighbors_support   \n",
      "2      Drug addicts as neighbors_support   \n",
      "3    Homosexuality – justifiable?_oppose   \n",
      "4     Prostitution – justifiable?_oppose   \n",
      "\n",
      "                                       Ideology_2  \\\n",
      "0              Prostitution – justifiable?_oppose   \n",
      "1                   Suicide – justifiable?_oppose   \n",
      "2                  Abortion – justifiable?_oppose   \n",
      "3              Different race as neighbors_oppose   \n",
      "4  Immigrants foreign workers as neighbors_oppose   \n",
      "\n",
      "                                        Ideology_3  \\\n",
      "0                   Divorce – justifiable?_support   \n",
      "1               Different race as neighbors_oppose   \n",
      "2  Someone accepting a bribe – justifiable?_oppose   \n",
      "3   Immigrants foreign workers as neighbors_oppose   \n",
      "4                  Homosexuals as neighbors_oppose   \n",
      "\n",
      "                                          Ideology_4  \\\n",
      "0  Avoiding a fare on public transport – justifia...   \n",
      "1  Justifiable: Claiming government benefits to w...   \n",
      "2           Cheating on taxes – justifiable?_support   \n",
      "3                     Divorce – justifiable?_support   \n",
      "4                    Abortion – justifiable?_support   \n",
      "\n",
      "                                        Ideology_5  \n",
      "0  Immigrants foreign workers as neighbors_support  \n",
      "1              Different race as neighbors_support  \n",
      "2               Prostitution – justifiable?_oppose  \n",
      "3                    Suicide – justifiable?_oppose  \n",
      "4  Someone accepting a bribe – justifiable?_oppose  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dictionary from the JSON file\n",
    "with open('variable_dict.json', 'r') as f:\n",
    "    variable_dict = json.load(f)\n",
    "\n",
    "# Read the CSV file with the top issues\n",
    "top_issues = pd.read_csv('top_issues.csv')\n",
    "\n",
    "# Function to replace codes with their description from the dictionary, while keeping the '_support' or '_oppose'\n",
    "def replace_with_description(issue_codes):\n",
    "    # Split by last underscore to separate the base code from the suffix\n",
    "    return [f\"{variable_dict.get(code.rsplit('_', 1)[0], f'Description Not Found: {code}')}{'_' + code.split('_')[-1]}\" for code in issue_codes]\n",
    "\n",
    "# Apply the function to each row of the 'top_issues' DataFrame\n",
    "top_issues_descriptive = top_issues.apply(lambda row: replace_with_description(row), axis=0)\n",
    "\n",
    "# Display the DataFrame with descriptive labels\n",
    "print(top_issues_descriptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your encoded dataset (df_encoded should be numeric)\n",
    "df_encoded = pd.read_csv(\"your_encoded_data.csv\")\n",
    "\n",
    "# Define the number of ideological types (topics) to test\n",
    "n_components_range = range(1, 11)  # Testing from 1 to 10 ideological types\n",
    "k_folds = 10  # Number of folds\n",
    "\n",
    "# Set up cross-validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to compute topic cohesion\n",
    "def topic_cohesion_score(topic_distributions, df_original):\n",
    "    \"\"\"\n",
    "    Measures how often top issue positions appear together in the original dataset.\n",
    "    Higher values indicate better cohesion.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for topic in topic_distributions:\n",
    "        # Get the top issues for the topic\n",
    "        top_issues = topic.argsort()[-5:]  # Top 5 most important features\n",
    "        co_occurrence = df_original.iloc[:, top_issues].mean().mean()  # Average co-occurrence\n",
    "        scores.append(co_occurrence)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Store the results\n",
    "best_cohesion = -np.inf\n",
    "best_n_components = None\n",
    "best_lda_model = None\n",
    "\n",
    "# Iterate over different numbers of ideological types\n",
    "for n_components in n_components_range:\n",
    "    cohesion_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(df_encoded):\n",
    "        train_data, test_data = df_encoded.iloc[train_index], df_encoded.iloc[test_index]\n",
    "\n",
    "        # Scale the data (LDA performs better with standardized inputs)\n",
    "        scaler = StandardScaler()\n",
    "        train_data_scaled = scaler.fit_transform(train_data)\n",
    "        test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "        # Train LDA model\n",
    "        lda = LatentDirichletAllocation(\n",
    "            n_components=n_components, \n",
    "            learning_method='batch',  # Use batch for stability\n",
    "            max_iter=10, \n",
    "            random_state=42\n",
    "        )\n",
    "        lda.fit(train_data_scaled)\n",
    "        \n",
    "        # Get topic distributions for the test set\n",
    "        test_topic_distributions = lda.transform(test_data_scaled)\n",
    "\n",
    "        # Compute topic cohesion\n",
    "        cohesion = topic_cohesion_score(lda.components_, df_encoded)\n",
    "        cohesion_scores.append(cohesion)\n",
    "\n",
    "    # Average cohesion score across all folds\n",
    "    avg_cohesion = np.mean(cohesion_scores)\n",
    "\n",
    "    # Save the best model\n",
    "    if avg_cohesion > best_cohesion:\n",
    "        best_cohesion = avg_cohesion\n",
    "        best_n_components = n_components\n",
    "        best_lda_model = lda\n",
    "\n",
    "# Print the best model parameters\n",
    "print(f\"Best Number of Ideological Types: {best_n_components}\")\n",
    "print(f\"Best Topic Cohesion Score: {best_cohesion}\")\n",
    "\n",
    "# Save the best LDA model\n",
    "import joblib\n",
    "joblib.dump(best_lda_model, \"best_lda_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
